[["topic-02.html", "4 Topic 02 4.1 Statistical Model 4.2 Simulation 4.3 Least-Squares Estimator 4.4 Sample Distribution of Least-Squares Estimator", " 4 Topic 02 4.1 Statistical Model Statistical model for each observations \\(i\\) (same \\(k\\) regressors across \\(m\\) equations), \\[\\begin{align*} \\underset{\\left(m \\times 1\\right)}{y_{i}} &amp;= \\underset{\\left(m\\times mk\\right)}{\\overline{X}_{i}} \\underset{\\left(mk \\times 1\\right)}{\\beta} + \\underset{\\left(m \\times 1\\right)}{e_{i}}, \\\\ \\begin{bmatrix} y_{1i} \\\\ y_{2i} \\\\ \\vdots \\\\ y_{mi} \\end{bmatrix} &amp;= \\begin{bmatrix} x_{1i}^{&#39;} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; x_{2i}^{&#39;} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; 0 \\\\ 0 &amp; 0&amp; \\cdots &amp; x_{mi}^{&#39;} \\end{bmatrix} + \\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\vdots \\\\ \\beta_{m} \\end{bmatrix} + \\begin{bmatrix} u_{1i} \\\\ u_{2i} \\\\ \\vdots \\\\ u_{mi} \\end{bmatrix}, \\end{align*}\\] with, \\(y_{ji}\\) and \\(e_{ji}\\) are scalars for \\(j=1,...,m\\). \\(x_{ji}\\) are \\(\\left(k \\times 1\\right)\\) matrix for \\(j=1,...,m\\). \\(\\beta\\) are \\(\\left(k \\times 1\\right)\\) matrix for \\(j=1,...,m\\). With the same \\(k\\) regressors across \\(m\\) equations this simplifies to, \\[\\begin{align*} \\underset{\\left(m \\times 1\\right)}{y_{i}} &amp;= \\underset{\\left(m\\times mk\\right)}{\\left(\\underset{\\left(m \\times m\\right)}{I_{m}} \\otimes \\underset{\\left(1\\times k\\right)}{x_{i}^{&#39;}}\\right)} \\underset{\\left(mk \\times 1\\right)}{\\beta} + \\underset{\\left(m \\times 1\\right)}{e_{i}}, \\end{align*}\\] thus, \\[\\begin{align*} \\overline{X}_{i} =\\underset{\\left(m \\times mk\\right)}{\\underset{\\left(m \\times m\\right)}{I_{m}} \\otimes \\underset{\\left(1 \\times k\\right)}{x_{i}^{&#39;}}} \\end{align*}\\] Statistical model in matrix notation across observations \\(i\\) (same \\(k\\) regressors across \\(m\\) equations), \\[\\begin{align*} \\underset{\\left(n \\times m\\right)}{Y} &amp;= \\underset{\\left(n\\times k\\right)}{X} \\underset{\\left(k \\times m\\right)}{B} + \\underset{\\left(n \\times k\\right)}{E}. \\end{align*}\\] 4.2 Simulation 4.2.1 Set up # clear workspace rm (list = ls(all=TRUE)) # set seed set.seed(1234567, kind=&quot;Mersenne-Twister&quot;) 4.2.2 Data Generating Process \\[\\begin{align*} y_t B + x_t A &amp;= u_t \\\\ u_t &amp;= u_{t-1} P + v_t \\\\ v_t &amp;= N\\left(0, V_t\\right) \\\\ V_t &amp;= S_t S_t^{&#39;} \\\\ S_t &amp;= C + D w_t \\\\ x_{1t} &amp;\\sim U\\left[x_{1l},x_{1u}\\right] \\\\ x_{1t} &amp;\\sim N \\left(\\mu_{x_{1}},\\sigma_{x_{1}}^2\\right) \\end{align*}\\] 4.2.3 Simulation # number of observations t &lt;- 2000 # parameters b1 &lt;- 0.6 b2 &lt;- 0.2 a1 &lt;- 0.4 a2 &lt;- -0.5 c11 &lt;- 1.0 c21 &lt;- 0.5 c22 &lt;- 2.0 d11 &lt;- 0.5 d21 &lt;- 0.2 d22 &lt;- 0.2 p11 &lt;- 0.8 p12 &lt;- 0.1 p21 &lt;- -0.2 p22 &lt;- 0.6 b &lt;- matrix(c(1, -b2, -b1, 1), nrow=2, byrow=T) a &lt;- matrix(c(-a1, 0, 0, -a2), nrow=2, byrow=T) c &lt;- matrix(c(c11, 0, c21, c22), nrow=2, byrow=T) d &lt;- matrix(c(d11, 0, d21, d22), nrow=2, byrow=T) # exogenous variables x &lt;- cbind(10*runif(t), 3*rnorm(t)) w &lt;- runif(t) # disturbances zeros &lt;- array(0, c(t,2)) u &lt;- zeros v &lt;- zeros for (i in 2:t) { l &lt;- c + d * w[i] v[i,] &lt;- rnorm(2) %*% t(l) u[i,1] &lt;- p11*u[i-1,1] + p12*u[i-1,2] + v[i,1] u[i,2] &lt;- p21*u[i-1,1] + p22*u[i-1,2] + v[i,2] } # simulate the reduced form y &lt;- zeros for (i in seq(t)) { y[i,] &lt;- -x[i,] %*% a %*% solve(b) + u[i,] %*% solve(b) } 4.2.4 Plots par(mfrow=c(1,2)) ts.plot(y[,1]) ts.plot(y[,2]) 4.2.5 Reduced form parameters # parameteres of the reduced form ab &lt;- -a %*% solve(b) ab ## [,1] [,2] ## [1,] 0.4545455 0.09090909 ## [2,] -0.3409091 -0.56818182 4.3 Least-Squares Estimator Use the stacked model in matrix notation across equations \\(j\\) and observations \\(i\\). # dimensions m &lt;- ncol(y);m ## [1] 2 t &lt;- nrow(y);t ## [1] 2000 n &lt;- t k &lt;- ncol(x);k ## [1] 2 # stack regressands and regressors Y &lt;- as.vector(y) # stack y over observations length(Y) ## [1] 4000 X &lt;- diag(m) %x% x # stack x over observations dim(X) ## [1] 4000 4 # estimation lm.res.01 &lt;- lm(Y ~ X - 1) lm.res.01$coefficients ## X1 X2 X3 X4 ## 0.44495050 -0.37735285 0.07649982 -0.60879807 # compare with reduced form parameters for simulation as.vector(ab) ## [1] 0.45454545 -0.34090909 0.09090909 -0.56818182 # expand residuals again e &lt;- matrix(lm.res.01$residuals, ncol = m) dim(e) ## [1] 2000 2 Sig.e &lt;- 1/t * t(e) %*% e Sig.e ## [,1] [,2] ## [1,] 10.861852 7.894577 ## [2,] 7.894577 9.537205 # compare with reduced form parameters for simulation Use the stacked model in matrix notation across observations \\(i\\). # estimation lm.res.02 &lt;- lm(y ~ x - 1) lm.res.02$coefficients ## [,1] [,2] ## x1 0.4449505 0.07649982 ## x2 -0.3773529 -0.60879807 # compare with reduced form parameters for simulation as.vector(ab) ## [1] 0.45454545 -0.34090909 0.09090909 -0.56818182 4.4 Sample Distribution of Least-Squares Estimator General distribution of \\(\\widehat{\\beta}\\): \\[\\begin{align*} \\sqrt{n} \\left(\\widehat{\\beta} - \\beta\\right) &amp;\\underset{d}{\\rightarrow}N\\left(0, V_{\\beta}\\right) \\\\ \\widehat{\\beta} &amp;\\underset{a}{\\sim}N\\left(\\beta, \\frac{V_{\\beta}}{n}\\right) \\end{align*}\\] General form: \\[\\begin{align*} V_{\\beta} = Q^{-1} \\Omega Q^{-1} \\end{align*}\\] 4.4.1 Population Quantities \\(\\Omega\\) in the population (robust w.r.t heteroskedasticity): \\[\\begin{align*} \\underset{\\left(mk\\times m\\right)}{\\overline{X}_{i}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{e_{i}} = \\left(\\begin{array}{c} \\underset{\\left(k\\times 1\\right)}{x_{1i}}\\underset{\\left(k\\times 1\\right)}{e_{1i}} \\\\ \\vdots \\\\ \\underset{\\left(k\\times 1\\right)}{x_{mi}}\\underset{\\left(1\\times 1\\right)}{e_{mi}} \\end{array}\\right) \\end{align*}\\] \\[\\begin{align*} \\frac{1}{\\sqrt{n}}\\sum_{i=1}^{n}\\underset{\\left(mk\\times m\\right)}{\\overline{X}_{i}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{e_{i}} \\underset{d}{\\rightarrow}N\\left(\\underset{\\left(mk\\times 1\\right)}{0}\\underset{\\left(mk\\times mk\\right)}{\\Omega}\\right) \\end{align*}\\] \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{\\Omega} &amp;= \\text{E}\\left[\\underset{\\left(mk\\times m\\right)}{\\overline{X}_{i}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{e_{i}^{\\phantom{&#39;}}}\\underset{\\left(1\\times m\\right)}{e_{i}^{&#39;}}\\underset{\\left(m\\times km\\right)}{\\overline{X}_{i}^{\\phantom{&#39;}}}\\right] \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\Omega}} &amp;= \\text{E} \\left[ \\underset{\\left(mk \\times m\\right)}{\\left( \\underset{\\left(m \\times m\\right)}{I_{m}^{\\phantom{&#39;}}} \\otimes \\underset{\\left(k \\times 1\\right)}{x_{i}^{\\phantom{&#39;}}} \\right)} \\underset{\\left(m \\times 1\\right)}{e_{i}^{\\phantom{&#39;}}} \\underset{\\left(1 \\times m\\right)}{e_{i}^{&#39;}} \\underset{\\left(m \\times mk\\right)}{\\left( \\underset{\\left(m \\times m\\right)}{I_{m}^{\\phantom{&#39;}}} \\otimes \\underset{\\left(1 \\times k\\right)}{x_{i}^{&#39;}} \\right)} \\right] \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\Omega}} &amp;= \\text{E}\\left[\\underset{\\left(m \\times 1\\right)}{e_{i}^{\\phantom{&#39;}}}\\underset{\\left(1 \\times m\\right)}{e_{i}^{&#39;}} \\otimes \\underset{\\left(k \\times 1\\right)}{x_{i}^{\\phantom{&#39;}}}\\underset{\\left(1 \\times k\\right)}{x_{i}^{&#39;}}\\right] \\end{align*}\\] \\(\\Omega\\) in the population (restricted to homoskedasticity): \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{\\Omega} &amp;= \\text{E}\\left[\\underset{\\left(mk\\times m\\right)}{\\overline{X}_{i}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{e_{i}^{\\phantom{&#39;}}}\\underset{\\left(1\\times m\\right)}{e_{i}^{&#39;}}\\underset{\\left(m\\times km\\right)}{\\overline{X}_{i}^{\\phantom{&#39;}}}\\right] \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\Omega}} &amp;= \\text{E} \\left[ \\underset{\\left(mk \\times m\\right)}{\\left( \\underset{\\left(m \\times m\\right)}{I_{m}^{\\phantom{&#39;}}} \\otimes \\underset{\\left(k \\times 1\\right)}{x_{i}^{\\phantom{&#39;}}} \\right)} \\underset{\\left(m \\times m\\right)}{\\Sigma} \\underset{\\left(m \\times mk\\right)}{\\left( \\underset{\\left(m \\times m\\right)}{I_{m}^{\\phantom{&#39;}}} \\otimes \\underset{\\left(1 \\times k\\right)}{x_{i}^{&#39;}} \\right)} \\right] \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\Omega}} &amp;= \\text{E}\\left[\\underset{\\left(m \\times m\\right)}{\\Sigma} \\otimes \\underset{\\left(k \\times 1\\right)}{x_{i}^{\\phantom{&#39;}}}\\underset{\\left(1 \\times k\\right)}{x_{i}^{&#39;}}\\right] \\end{align*}\\] with \\[\\begin{align*} \\underset{\\left(m \\times m\\right)}{\\Sigma} = \\text{E}\\left[\\underset{\\left(m \\times 1\\right)}{e_{i}^{\\phantom{&#39;}}} \\underset{\\left(1 \\times m\\right)}{e_{i}^{&#39;}} \\right] \\end{align*}\\] \\(\\Omega\\) in the population (robust w.r.t heteroskedasticity and serial correlation): \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{\\Omega} &amp;= \\sum_{l=-\\infty}^{\\infty} \\text{E}\\left[\\underset{\\left(mk\\times m\\right)}{\\overline{X}_{t-l}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{e_{t-l}^{\\phantom{&#39;}}}\\underset{\\left(1\\times m\\right)}{e_{t}^{&#39;}}\\underset{\\left(m\\times km\\right)}{\\overline{X}_{t}^{\\phantom{&#39;}}}\\right] \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\Omega}} &amp;= \\sum_{l=-\\infty}^{\\infty} \\text{E} \\left[ \\underset{\\left(mk \\times m\\right)}{\\left( \\underset{\\left(m \\times m\\right)}{I_{m}^{\\phantom{&#39;}}} \\otimes \\underset{\\left(k \\times 1\\right)}{x_{t-l}^{\\phantom{&#39;}}} \\right)} \\underset{\\left(m \\times 1\\right)}{e_{t-l}^{\\phantom{&#39;}}} \\underset{\\left(1 \\times m\\right)}{e_{t}^{&#39;}} \\underset{\\left(m \\times mk\\right)}{\\left( \\underset{\\left(m \\times m\\right)}{I_{m}^{\\phantom{&#39;}}} \\otimes \\underset{\\left(1 \\times k\\right)}{x_{t}^{&#39;}} \\right)} \\right] \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\Omega}} &amp;= \\sum_{l=-\\infty}^{\\infty} \\text{E}\\left[\\underset{\\left(m \\times 1\\right)}{e_{t-l}^{\\phantom{&#39;}}}\\underset{\\left(1 \\times m\\right)}{e_{t}^{&#39;}} \\otimes \\underset{\\left(k \\times 1\\right)}{x_{t-l}^{\\phantom{&#39;}}}\\underset{\\left(1 \\times k\\right)}{x_{t}^{&#39;}}\\right] \\end{align*}\\] \\(Q\\) in the population: \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{Q} &amp;= \\text{E} \\left[ \\overline{X}_{i}^{&#39;} \\overline{X}_{i} \\right] \\\\ \\phantom{Q} &amp;= \\text{E} \\left[ \\left( I_{m} \\otimes x_{i} \\right) \\left( I_{m} \\otimes x_{i}^{&#39;} \\right) \\right] \\\\ \\phantom{Q} &amp;= I_{m} \\otimes \\text{E} \\left[ x_{i}^{&#39;} x_{i} \\right] \\end{align*}\\] 4.4.2 Sample Quantities Sample counterpart of \\(\\Omega\\) (robust w.r.t heteroskedasticity): \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}} &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n} \\underset{\\left(mk\\times m\\right)}{\\overline{X}_{i}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{\\widehat{e}_{i}}\\underset{\\left(1\\times m\\right)}{\\widehat{e}_{i}^{&#39;}}\\underset{\\left(m\\times km\\right)}{\\overline{X}_{i}} \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}}} &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n} \\left( \\left( I_{m} \\otimes x_{i} \\right) \\widehat{e}_{i} \\widehat{e}_{i}^{&#39;} \\left( I_{m} \\otimes x_{i}^{&#39;} \\right) \\right) \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}}} &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n}\\left(\\widehat{e}_{i}\\widehat{e}_{i}^{&#39;} \\otimes x_{i}x_{i}^{&#39;}\\right) \\end{align*}\\] xe.01 &lt;- matrix(seq(1,t*m*k), nrow = t, ncol = m*k) for (i in 1:t) { for (j in 1:m) { xe.01[i,(k*(j-1)+1):(k*j)] &lt;- x[i,,drop=F] * e[i,j,drop=T] } } Omega.02.hat &lt;- 1/(n^2) * (t(xe.01) %*% xe.01) Omega.02.hat ## [,1] [,2] [,3] [,4] ## [1,] 0.190994710 -0.001527710 0.1362075134 -0.0006610410 ## [2,] -0.001527710 0.055255030 -0.0006610410 0.0401939360 ## [3,] 0.136207513 -0.000661041 0.1612209878 0.0001705627 ## [4,] -0.000661041 0.040193936 0.0001705627 0.0459240224 Compare with the results of the sandwich package. Omega.02.hat * n ## [,1] [,2] [,3] [,4] ## [1,] 381.989420 -3.055420 272.4150269 -1.3220820 ## [2,] -3.055420 110.510060 -1.3220820 80.3878720 ## [3,] 272.415027 -1.322082 322.4419756 0.3411254 ## [4,] -1.322082 80.387872 0.3411254 91.8480448 sandwich::meat(lm.res.02) ## :x1 :x2 :x1 :x2 ## :x1 381.989420 -3.055420 272.4150269 -1.3220820 ## :x2 -3.055420 110.510060 -1.3220820 80.3878720 ## :x1 272.415027 -1.322082 322.4419756 0.3411254 ## :x2 -1.322082 80.387872 0.3411254 91.8480448 Sample counterpart of \\(\\Omega\\) (restricted to homoskedasticity): \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}} &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n} \\underset{\\left(mk\\times m\\right)}{\\overline{X}_{i}^{&#39;}}\\underset{\\left(m\\times 1\\right)}{\\widehat{e}_{i}}\\underset{\\left(1\\times m\\right)}{\\widehat{e}_{i}^{&#39;}}\\underset{\\left(m\\times km\\right)}{\\overline{X}_{i}} \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}}} &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n} \\left( \\left( I_{m} \\otimes x_{i} \\right) \\widehat{\\Sigma} \\left( I_{m} \\otimes x_{i}^{&#39;} \\right) \\right) \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}}} &amp;= \\frac{1}{n^2} \\sum_{i=1}^{n} \\left( \\widehat{\\Sigma} \\otimes x_{i}^{\\phantom{&#39;}}x_{i}^{&#39;} \\right) \\\\ \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}}} &amp;= \\frac{1}{n^2} \\left( \\widehat{\\Sigma} \\otimes \\sum_{i=1}^{n} x_{i}^{\\phantom{&#39;}}x_{i}^{&#39;} \\right) \\end{align*}\\] with \\[\\begin{align*} \\widehat{\\Sigma} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( {e_{i} e_{i}^{&#39;}} \\right) \\end{align*}\\] Omega.01.hat &lt;- 1/(n^2) * ((t(e) %*% e) / n) %x% (t(x) %*% x) Omega.01.hat ## [,1] [,2] [,3] [,4] ## [1,] 0.1841746922 -0.0006837816 0.1338612722 -0.0004969840 ## [2,] -0.0006837816 0.0490580641 -0.0004969840 0.0356562283 ## [3,] 0.1338612722 -0.0004969840 0.1617138343 -0.0006003917 ## [4,] -0.0004969840 0.0356562283 -0.0006003917 0.0430752323 Sample counterpart of \\(\\Omega\\) (robust w.r.t heteroskedasticity and serial correlation): library(sandwich) # sandwich::vcovHAC(lm.res.02) # # Error in umat - res : non-conformable arrays sandwich___bwAndrews &lt;- function (x, order.by = NULL, kernel = c(&quot;Quadratic Spectral&quot;, &quot;Truncated&quot;, &quot;Bartlett&quot;, &quot;Parzen&quot;, &quot;Tukey-Hanning&quot;), approx = c(&quot;AR(1)&quot;, &quot;ARMA(1,1)&quot;), weights = NULL, prewhite = 1, ar.method = &quot;ols&quot;, data = list(), ...) { # inputs x &lt;- lm.res.02 order.by &lt;- NULL kernel &lt;- c(&quot;Quadratic Spectral&quot;) approx &lt;- c(&quot;AR(1)&quot;) weights &lt;- NULL prewhite &lt;- 1 ar.method &lt;- &quot;ols&quot; data = list() if (is.list(x) &amp;&amp; !is.null(x$na.action)) { class(x$na.action) &lt;- &quot;omit&quot; } kernel &lt;- match.arg(kernel) approx &lt;- match.arg(approx) prewhite &lt;- as.integer(prewhite) umat &lt;- if (inherits(x, &quot;matrix&quot;)) { x } else { estfun(x)[, , drop = FALSE] } if (zoo::is.zoo(umat)) { umat &lt;- as.matrix(coredata(umat)) } n &lt;- nrow(umat) k &lt;- ncol(umat) if (!is.null(order.by)) { if (inherits(order.by, &quot;formula&quot;)) { z &lt;- model.matrix(order.by, data = data) z &lt;- as.vector(z[, ncol(z)]) } else { z &lt;- order.by } index &lt;- order(z) } else { index &lt;- 1:n } umat &lt;- umat[index, , drop = FALSE] # problem umat (n x m*k) - res () if (is.null(weights)) { weights &lt;- rep(1, k) unames &lt;- colnames(umat) if (!is.null(unames) &amp;&amp; &quot;(Intercept)&quot; %in% unames) { weights[which(unames == &quot;(Intercept)&quot;)] &lt;- 0 } else { # res &lt;- try(as.vector(rowMeans(estfun(x)/model.matrix(x), na.rm = TRUE)), silent = TRUE) # MM: added for m=2! tmp &lt;- model.matrix(x) for (i in 1:ncol(residuals(x))) { tmp &lt;- cbind(tmp, model.matrix(x)) } res &lt;- try(as.vector(rowMeans(estfun(x)/cbind(model.matrix(x), model.matrix(x)), na.rm = TRUE)), silent = TRUE) if (inherits(res, &quot;try-error&quot;)) { res &lt;- try(residuals(x), silent = TRUE) } if (!inherits(res, &quot;try-error&quot;)) { weights[which(colSums((umat - res)^2) &lt; 1e-16)] &lt;- 0 } } if (isTRUE(all.equal(weights, rep(0, k)))) { weights &lt;- rep(1, k) } } else { weights &lt;- rep(weights, length.out = k) } if (length(weights) &lt; 2) { weights &lt;- 1 } if (prewhite &gt; 0) { var.fit &lt;- ar(umat, order.max = prewhite, demean = FALSE, aic = FALSE, method = ar.method) if (inherits(var.fit, &quot;try-error&quot;)) { stop(sprintf(&quot;VAR(%i) prewhitening of estimating functions failed&quot;, prewhite)) } umat &lt;- as.matrix(na.omit(var.fit$resid)) n &lt;- n - prewhite } if (approx == &quot;AR(1)&quot;) { fitAR1 &lt;- function(x) { rval &lt;- ar(x, order.max = 1, aic = FALSE, method = &quot;ols&quot;) rval &lt;- c(rval$ar, sqrt(rval$var.pred)) names(rval) &lt;- c(&quot;rho&quot;, &quot;sigma&quot;) return(rval) } ar.coef &lt;- apply(umat, 2, fitAR1) denum &lt;- sum(weights * (ar.coef[&quot;sigma&quot;, ]/(1 - ar.coef[&quot;rho&quot;, ]))^4) alpha2 &lt;- sum(weights * 4 * ar.coef[&quot;rho&quot;, ]^2 * ar.coef[&quot;sigma&quot;, ]^4/(1 - ar.coef[&quot;rho&quot;, ])^8)/denum alpha1 &lt;- sum(weights * 4 * ar.coef[&quot;rho&quot;, ]^2 * ar.coef[&quot;sigma&quot;, ]^4/((1 - ar.coef[&quot;rho&quot;, ])^6 * (1 + ar.coef[&quot;rho&quot;, ])^2))/denum } else { fitARMA11 &lt;- function(x) { rval &lt;- arima(x, order = c(1, 0, 1), include.mean = FALSE) rval &lt;- c(rval$coef, sqrt(rval$sigma2)) names(rval) &lt;- c(&quot;rho&quot;, &quot;psi&quot;, &quot;sigma&quot;) return(rval) } arma.coef &lt;- apply(umat, 2, fitARMA11) denum &lt;- sum(weights * ((1 + arma.coef[&quot;psi&quot;, ]) * arma.coef[&quot;sigma&quot;, ]/(1 - arma.coef[&quot;rho&quot;, ]))^4) alpha2 &lt;- sum(weights * 4 * ((1 + arma.coef[&quot;rho&quot;, ] * arma.coef[&quot;psi&quot;, ]) * (arma.coef[&quot;rho&quot;, ] + arma.coef[&quot;psi&quot;, ]))^2 * arma.coef[&quot;sigma&quot;, ]^4/(1 - arma.coef[&quot;rho&quot;, ])^8)/denum alpha1 &lt;- sum(weights * 4 * ((1 + arma.coef[&quot;rho&quot;, ] * arma.coef[&quot;psi&quot;, ]) * (arma.coef[&quot;rho&quot;, ] + arma.coef[&quot;psi&quot;, ]))^2 * arma.coef[&quot;sigma&quot;, ]^4/((1 - arma.coef[&quot;rho&quot;, ])^6 * (1 + arma.coef[&quot;rho&quot;, ])^2))/denum } rval &lt;- switch(kernel, Truncated = { 0.6611 * (n * alpha2)^(1/5) }, Bartlett = { 1.1447 * (n * alpha1)^(1/3) }, Parzen = { 2.6614 * (n * alpha2)^(1/5) }, `Tukey-Hanning` = { 1.7462 * (n * alpha2)^(1/5) }, `Quadratic Spectral` = { 1.3221 * (n * alpha2)^(1/5) } ) return(rval) } sandwich__kweights &lt;- function (x, kernel = c(&quot;Truncated&quot;, &quot;Bartlett&quot;, &quot;Parzen&quot;, &quot;Tukey-Hanning&quot;, &quot;Quadratic Spectral&quot;), normalize = FALSE) { kernel &lt;- match.arg(kernel, c(&quot;Truncated&quot;, &quot;Bartlett&quot;, &quot;Parzen&quot;, &quot;Tukey-Hanning&quot;, &quot;Quadratic Spectral&quot;)) if (normalize) { ca &lt;- switch(kernel, Truncated = 2, Bartlett = 2/3, Parzen = 0.539285, `Tukey-Hanning` = 3/4, `Quadratic Spectral` = 1) } else { ca &lt;- 1 } switch(kernel, Truncated = { ifelse(ca * abs(x) &gt; 1, 0, 1) }, Bartlett = { ifelse(ca * abs(x) &gt; 1, 0, 1 - abs(ca * x)) }, Parzen = { ifelse(ca * abs(x) &gt; 1, 0, ifelse(ca * abs(x) &lt; 0.5, 1 - 6 * (ca * x)^2 + 6 * abs(ca * x)^3, 2 * (1 - abs(ca * x))^3)) }, `Tukey-Hanning` = { ifelse(ca * abs(x) &gt; 1, 0, (1 + cos(pi * ca * x))/2) }, `Quadratic Spectral` = { qs &lt;- function(x) { y &lt;- 6 * pi * x/5 3 * (1/y)^2 * (sin(y)/y - cos(y)) } w &lt;- qs(x) if (length(ix &lt;- which(abs(x) &lt; 0.001)) &gt; 0L) { cf &lt;- 1e+06 * log(qs(0.001)) w[ix] &lt;- exp(cf * x[ix]^2) } w} ) } sandwich__weightsAndrews &lt;- function (x, order.by = NULL, bw = bwAndrews, kernel = c(&quot;Quadratic Spectral&quot;, &quot;Truncated&quot;, &quot;Bartlett&quot;, &quot;Parzen&quot;, &quot;Tukey-Hanning&quot;), prewhite = 1, ar.method = &quot;ols&quot;, tol = 1e-07, data = list(), verbose = FALSE, ...) { # # inputs # x &lt;- lm.res.02 # order.by &lt;- NULL # bw &lt;- bwAndrews # kernel &lt;- NULL # prewhite &lt;- 1 # ar.method &lt;- &quot;ols&quot; # tol &lt;- 1e-07 # verbose &lt;- FALSE # data = list() if (is.list(x) &amp;&amp; !is.null(x$na.action)) { class(x$na.action) &lt;- &quot;omit&quot; } kernel &lt;- match.arg(kernel) # call bandwidth function bw(), bwAndrews() if (is.function(bw)) { # bw &lt;- bw(x, order.by = order.by, kernel = kernel, prewhite = prewhite, data = data, ar.method = ar.method, ...) # bw &lt;- bw(x, order.by = order.by, kernel = kernel, prewhite = prewhite, data = data, ar.method = ar.method) bw &lt;- sandwich___bwAndrews(x, order.by = order.by, kernel = kernel, prewhite = prewhite, data = data, ar.method = ar.method) } if (verbose) { cat(paste(&quot;\\nBandwidth chosen:&quot;, format(bw), &quot;\\n&quot;)) } n &lt;- NROW(estfun(x)) - as.integer(prewhite) # call kernel weights function kweights(), weightsAndrews() # weights &lt;- kweights(0:(n - 1)/bw, kernel = kernel) weights &lt;- sandwich__kweights(0:(n - 1)/bw, kernel = kernel) weights &lt;- weights[1:max(which(abs(weights) &gt; tol))] return(weights) } sandwich__meatHAC &lt;- function(x, order.by = NULL, prewhite = FALSE, weights = weightsAndrews, adjust = TRUE, diagnostics = FALSE, ar.method = &quot;ols&quot;, data = list(), ...) { # # inputs # x &lt;- lm.res.02 # order.by &lt;- NULL # prewhite &lt;- FALSE # weights &lt;- weightsAndrews # adjust &lt;- TRUE # diagnostics &lt;- FALSE # ar.method &lt;- &quot;ols&quot; # data &lt;- list() if (is.list(x) &amp;&amp; !is.null(x$na.action)) { class(x$na.action) &lt;- &quot;omit&quot; } prewhite &lt;- as.integer(prewhite) # umat &lt;- estfun(x, ...)[, , drop = FALSE] umat &lt;- estfun(x)[, , drop = FALSE] if (zoo::is.zoo(umat)) { umat &lt;- as.matrix(coredata(umat)) } # MM: check head(xe.01) head(umat) # (t x m*k) n.orig &lt;- n &lt;- nrow(umat) k &lt;- ncol(umat) if (!is.null(order.by)) { if (inherits(order.by, &quot;formula&quot;)) { z &lt;- model.matrix(order.by, data = data) z &lt;- as.vector(z[, ncol(z)]) } else { z &lt;- order.by } index &lt;- order(z) } else { index &lt;- 1:n } umat &lt;- umat[index, , drop = FALSE] if (prewhite &gt; 0) { var.fit &lt;- try(ar(umat, order.max = prewhite, demean = FALSE, aic = FALSE, method = ar.method)) if (inherits(var.fit, &quot;try-error&quot;)) { stop(sprintf(&quot;VAR(%i) prewhitening of estimating functions failed&quot;, prewhite)) } if (k &gt; 1) { D &lt;- solve(diag(ncol(umat)) - apply(var.fit$ar, 2:3, sum)) } else { D &lt;- as.matrix(1/(1 - sum(var.fit$ar))) } umat &lt;- as.matrix(na.omit(var.fit$resid)) n &lt;- n - prewhite } # call weight function weights(), weightsAndrews() if (is.function(weights)) { # weights &lt;- weights(x, order.by = order.by, prewhite = prewhite, ar.method = ar.method, data = data) weights &lt;- sandwich__weightsAndrews(x, order.by = order.by, prewhite = prewhite, ar.method = ar.method, data = data) } if (length(weights) &gt; n) { warning(&quot;more weights than observations, only first n used&quot;) weights &lt;- weights[1:n] } utu &lt;- 0.5 * crossprod(umat) * weights[1] wsum &lt;- n * weights[1]/2 w2sum &lt;- n * weights[1]^2/2 if (length(weights) &gt; 1) { for (ii in 2:length(weights)) { utu &lt;- utu + weights[ii] * crossprod(umat[1:(n - ii + 1), , drop = FALSE], umat[ii:n, , drop = FALSE]) wsum &lt;- wsum + (n - ii + 1) * weights[ii] w2sum &lt;- w2sum + (n - ii + 1) * weights[ii]^2 } } utu &lt;- utu + t(utu) if (adjust) { utu &lt;- n.orig/(n.orig - k) * utu } if (prewhite &gt; 0) { utu &lt;- crossprod(t(D), utu) %*% t(D) } wsum &lt;- 2 * wsum w2sum &lt;- 2 * w2sum bc &lt;- n^2/(n^2 - wsum) df &lt;- n^2/w2sum rval &lt;- utu/n.orig if (diagnostics) { attr(rval, &quot;diagnostics&quot;) &lt;- list(bias.correction = bc, df = df) } return(rval) } tmp &lt;- sandwich__meatHAC(x = lm.res.02, order.by = NULL, prewhite = FALSE, weights = weightsAndrews, adjust = TRUE, diagnostics = FALSE, ar.method = &quot;ols&quot;, data = list()) sandwich::sandwich(lm.res.02, meat. = tmp) ## :x1 :x2 :x1 :x2 ## :x1 3.338048e-04 -7.011226e-06 2.193828e-04 3.111540e-06 ## :x2 -7.011226e-06 6.468170e-04 -2.118039e-06 4.611313e-04 ## :x1 2.193828e-04 -2.118039e-06 2.452446e-04 1.272432e-05 ## :x2 3.111540e-06 4.611313e-04 1.272432e-05 5.340884e-04 vcovHC(lm.res.02) ## :x1 :x2 :x1 :x2 ## :x1 1.665635e-04 -1.242717e-07 1.187889e-04 1.351467e-06 ## :x2 -1.242717e-07 6.800810e-04 1.351467e-06 4.947265e-04 ## :x1 1.187889e-04 1.351467e-06 1.406095e-04 4.635397e-06 ## :x2 1.351467e-06 4.947265e-04 4.635397e-06 5.652163e-04 Sample counterpart of \\(Q\\): \\[\\begin{align*} \\underset{\\left(mk\\times mk\\right)}{Q} &amp;= \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\overline{X}_{i}^{&#39;} \\overline{X}_{i} \\right) \\\\ \\phantom{Q} &amp;= \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\left( I_{m} \\otimes x_{i} \\right) \\left( I_{m} \\otimes x_{i}^{&#39;} \\right) \\right) \\\\ \\phantom{Q} &amp;= \\frac{1}{n} \\left( I_{m} \\otimes \\sum_{i=1}^{n} \\left( x_{i}^{&#39;} x_{i} \\right) \\right) \\end{align*}\\] Q.hat &lt;- 1/n * diag(m) %x% (t(x) %*% x) Q.hat ## [,1] [,2] [,3] [,4] ## [1,] 33.9122085 -0.1259052 0.0000000 0.0000000 ## [2,] -0.1259052 9.0330940 0.0000000 0.0000000 ## [3,] 0.0000000 0.0000000 33.9122085 -0.1259052 ## [4,] 0.0000000 0.0000000 -0.1259052 9.0330940 Compare with the results of the sandwich package. solve(Q.hat) ## [,1] [,2] [,3] [,4] ## [1,] 0.0294894316 0.0004110299 0.0000000000 0.0000000000 ## [2,] 0.0004110299 0.1107097697 0.0000000000 0.0000000000 ## [3,] 0.0000000000 0.0000000000 0.0294894316 0.0004110299 ## [4,] 0.0000000000 0.0000000000 0.0004110299 0.1107097697 sandwich::bread(lm.res.02) ## :x1 :x2 :x1 :x2 ## :x1 0.0294894316 0.0004110299 0.0000000000 0.0000000000 ## :x2 0.0004110299 0.1107097697 0.0000000000 0.0000000000 ## :x1 0.0000000000 0.0000000000 0.0294894316 0.0004110299 ## :x2 0.0000000000 0.0000000000 0.0004110299 0.1107097697 Sample counterpart of \\(V_{\\beta}\\) (robust w.r.t heteroskedasticity): \\[\\begin{align*} \\widehat{V}_{\\widehat{\\beta}} &amp;= \\widehat{Q}^{-1} \\widehat{\\Omega} \\widehat{Q}^{-1} \\\\ \\phantom{\\widehat{V}_{\\widehat{\\beta}}} &amp;= \\left(\\frac{1}{n} \\left( I_{m} \\otimes \\sum_{i=1}^{n} \\left( x_{i}^{&#39;} x_{i} \\right) \\right)\\right)^{-1} \\frac{1}{n^2} \\sum_{i=1}^{n}\\left(\\widehat{e}_{i}\\widehat{e}_{i}^{&#39;} \\otimes x_{i}x_{i}^{&#39;}\\right) \\left(\\frac{1}{n} \\left( I_{m} \\otimes \\sum_{i=1}^{n} \\left( x_{i}^{&#39;} x_{i} \\right) \\right)\\right)^{-1} \\end{align*}\\] V.b.hat.02 &lt;- solve(Q.hat) %*% Omega.02.hat %*% solve(Q.hat) V.b.hat.02 ## [,1] [,2] [,3] [,4] ## [1,] 1.660664e-04 -1.584418e-07 1.184404e-04 1.321745e-06 ## [2,] -1.584418e-07 6.771350e-04 1.321745e-06 4.926060e-04 ## [3,] 1.184404e-04 1.321745e-06 1.402139e-04 4.600816e-06 ## [4,] 1.321745e-06 4.926060e-04 4.600816e-06 5.629176e-04 Compare with the results of the sandwich package. V.b.hat.02 ## [,1] [,2] [,3] [,4] ## [1,] 1.660664e-04 -1.584418e-07 1.184404e-04 1.321745e-06 ## [2,] -1.584418e-07 6.771350e-04 1.321745e-06 4.926060e-04 ## [3,] 1.184404e-04 1.321745e-06 1.402139e-04 4.600816e-06 ## [4,] 1.321745e-06 4.926060e-04 4.600816e-06 5.629176e-04 sandwich::vcovHC(lm.res.02, type = &quot;HC0&quot;) ## :x1 :x2 :x1 :x2 ## :x1 1.660664e-04 -1.584418e-07 1.184404e-04 1.321745e-06 ## :x2 -1.584418e-07 6.771350e-04 1.321745e-06 4.926060e-04 ## :x1 1.184404e-04 1.321745e-06 1.402139e-04 4.600816e-06 ## :x2 1.321745e-06 4.926060e-04 4.600816e-06 5.629176e-04 Sample counterpart of \\(V_{\\beta}\\) (restricted to homoskedasticity): \\[\\begin{align*} \\widehat{V}_{\\widehat{\\beta}} &amp;= \\widehat{Q}^{-1} \\widehat{\\Omega} \\widehat{Q}^{-1} \\\\ \\phantom{\\widehat{V}_{\\widehat{\\beta}}} &amp;= \\left(\\frac{1}{n} \\left( I_{m} \\otimes \\sum_{i=1}^{n} \\left( x_{i}^{&#39;} x_{i} \\right) \\right)\\right)^{-1} \\frac{1}{n^2} \\sum_{i=1}^{n} \\left( \\left( I_{m} \\otimes x_{i} \\right) \\widehat{\\Sigma} \\left( I_{m} \\otimes x_{i}^{&#39;} \\right) \\right) \\left(\\frac{1}{n} \\left( I_{m} \\otimes \\sum_{i=1}^{n} \\left( x_{i}^{&#39;} x_{i} \\right) \\right)\\right)^{-1} \\\\ \\phantom{\\widehat{V}_{\\widehat{\\beta}}} \\phantom{\\underset{\\left(mk\\times mk\\right)}{\\widehat{\\Omega}}} &amp;= \\frac{1}{n^2} \\left( \\widehat{\\Sigma} \\otimes \\sum_{i=1}^{n} x_{i}^{\\phantom{&#39;}}x_{i}^{&#39;} \\right) \\end{align*}\\] V.b.hat.01 &lt;- solve(Q.hat) %*% Omega.01.hat %*% solve(Q.hat) V.b.hat.01 ## [,1] [,2] [,3] [,4] ## [1,] 1.601549e-04 2.232273e-06 1.164033e-04 1.622454e-06 ## [2,] 2.232273e-06 6.012566e-04 1.622454e-06 4.370034e-04 ## [3,] 1.164033e-04 1.622454e-06 1.406234e-04 1.960038e-06 ## [4,] 1.622454e-06 4.370034e-04 1.960038e-06 5.279309e-04 Compare with results of the stats package. V.b.hat.01 * n/(n-2) ## [,1] [,2] [,3] [,4] ## [1,] 1.603152e-04 2.234508e-06 1.165198e-04 1.624078e-06 ## [2,] 2.234508e-06 6.018584e-04 1.624078e-06 4.374408e-04 ## [3,] 1.165198e-04 1.624078e-06 1.407641e-04 1.962000e-06 ## [4,] 1.624078e-06 4.374408e-04 1.962000e-06 5.284593e-04 vcov(lm.res.02) ## :x1 :x2 :x1 :x2 ## :x1 1.603152e-04 2.234508e-06 1.165198e-04 1.624078e-06 ## :x2 2.234508e-06 6.018584e-04 1.624078e-06 4.374408e-04 ## :x1 1.165198e-04 1.624078e-06 1.407641e-04 1.962000e-06 ## :x2 1.624078e-06 4.374408e-04 1.962000e-06 5.284593e-04 class(lm.res.02) ## [1] &quot;mlm&quot; &quot;lm&quot; Sample counterpart of \\(V_{\\beta}\\) (robust w.r.t heteroskedasticity and serial correlation): â€¦ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
