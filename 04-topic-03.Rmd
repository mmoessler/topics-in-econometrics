
# Topic 03

```{r,include=FALSE}

library(knitr)
knitr::opts_chunk$set(
  include = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  eval = TRUE
  # fig.height = 8,
  # fig.width = 10,
  # fig.align = 'center'
  )
# options(scipen=1)
# options(width=9999)
# # See: https://stackoverflow.com/questions/36230790/missing-horizontal-scroll-bar-in-r-markdown-html-code-chunks-and-output

```

## Statistical Model

Cointegrating regression model

\begin{align}
y_{1t} &= \mu_0 + \mu_1 t + B y_{2t} + u_{1t} \\
y_{2t} &= y_{2t-1} + u_{2t}
\end{align}

with

\begin{align}
\begin{bmatrix} u_{1t} \\ u_{2t} \end{bmatrix} = C\left(L\right) \varepsilon_{t},
\end{align}

## Estimation

Correction due to endogeneity in $y_{2t}$ due to cointegration link between $y_{1t}$ and $y_{2t}$.

\begin{align}
y_{1t}^{*} = y_{1t} - \widehat{\Omega}_{1y_2}\widehat{\Omega}_{y_2 y_2}^{-1}\Delta y_{2t}
\end{align}

where $\widehat{\Omega}_{1y_2}$ is an estimate for the long-run covariances matrix of $u_{1t}$ and $y_2$ and where $\widehat{\Omega}_{y_2 y_2}$ is an estimate for the long-run covariances matrix of $y_2$ and $y_2$. 

Correlation due to serial correlation in $u_{1t}$.

\begin{align}
\widehat{\Delta}_{1y_2}^{*} = \widehat{\Delta}_{1y_2} - \widehat{\Omega}_{1y_2}\widehat{\Omega}_{y_2 y_2}^{-1}\widehat{\Delta}_{y_2 y_2}
\end{align}

Fully modified (FM) OLS estimator

\begin{align}
\widehat{B}^{*} = \left(Y_{1}^{*'}Y_{2} - T \widehat{\Delta}_{1y_2}^{*}\right)\left(Y_{2}^{'}Y_{2}\right)^{-1}
\end{align}

## Sample Distribution

From Theorem 4.1 we get the (potentially degenerated) asymptotics for the full coefficnet matrix $\widehat{B}^{*}$

\begin{align}
\sqrt{T}\left(\widehat{B}^{*}-B^{*}\right) &\underset{d}{\rightarrow} N\left(0,\left(I\otimes H_{1} \Sigma_{11}^{-1}\right)\Omega_{\varphi\varphi}\left(I\otimes \Sigma_{11}^{-1}H_{1}^{'}\right)\right)
\\
\phantom{\sqrt{T}\left(\widehat{B}^{*}-B^{*}\right)} &\underset{d}{\rightarrow} N\left(0, \Sigma_{00} \otimes H_{1} \Sigma_{11}^{-1} H_{1}^{'} \right)
\end{align}

with

\begin{align}
\Omega_{\varphi\varphi} &= \sum_{j=-\infty}^{\infty} \text{E}\left( \left(u_{1t}, u_{2t}\right)\left(u_{1t+j}, u_{2t+j}\right)^{'} \otimes u_{1t} u_{1t+j}^{'} \right)
\\
\Sigma_{00} &= \text{E}\left(\left(u_{1t}, u_{2t}\right)^{'}\left(u_{1t}, u_{2t}\right)\right)
\\
\Sigma_{11} &= \text{E}\left(u_{1t}^{'}u_{1t}\right)
\end{align}



### Case 1

*see: Hamilton, 1994, p. 602*

<span style="text-decoration: underline; font-size: 16pt">Assumptions</span>

* Gaussian system
* $y_{2t}$ follows a random walk
* $u_{1t}$ is white noise and uncorrelated with $u_{1t}$ for all $t$ and $\tau$

<span style="text-decoration: underline; font-size: 16pt">Finite sample results</span>

\begin{align}

\left(\underset{\left(m \times 1\right)}{R_{\alpha}} \underset{\left(1\times 1\right)}{\widehat{\alpha}_{T}} + \underset{\left(m \times g\right)}{R_{\gamma}} \underset{\left(g\times 1\right)}{\widehat{\gamma}_{T}}-\underset{\left(m\times 1\right)}{r}\right)^{'}

&\times \\

\left(\underset{

\left(1\times 1\right)}{S_T^2}

\begin{pmatrix}
\underset{\left(m \times 1\right)}{R_{\alpha}} & \underset{\left(m \times g\right)}{R_{\gamma}}
\end{pmatrix}

\begin{pmatrix}
\underset{\left(1 \times 1\right)}{T} & \underset{\left(1 \times g\right)}{\sum y_{2t}^{'}} \\
\underset{\left(g \times 1\right)}{\sum y_{2t}} & \underset{\left(g \times g\right)}{\sum y_{2t}y_{2t}^{'}}
\end{pmatrix}^{-1}

\begin{pmatrix}
\underset{\left(1 \times m\right)}{R_{\alpha}^{'}} \\ \underset{\left(g \times m\right)}{R_{\gamma}^{'}}
\end{pmatrix}

\right)^{-1}

&\times \\

\left(\underset{\left(m \times 1\right)}{R_{\alpha}} \underset{\left(1\times 1\right)}{\widehat{\alpha_{T}}} + \underset{\left(m \times g\right)}{R_{\gamma}} \underset{\left(g\times 1\right)}{\widehat{\gamma_{T}}}-\underset{\left(m\times 1\right)}{r}\right)^{'}

&\div m

\end{align}

with

\begin{align}

\underset{\left(1\times 1\right)}{s_{T}^{2}} = \frac{1}{T-n}\sum_{t=1}^{T}\left( \underset{\left(1\times 1\right)}{y_{1t}} - \underset{\left(1\times 1\right)}{\widehat{\alpha}_{t}} - \underset{\left(1\times g\right)}{\widehat{\gamma}_{t}^{'}} \underset{\left(g\times 1\right)}{y_{2t}} \right)^{2}

\end{align}





\begin{align}

\left(
\underset{\left(m \times k\right)}{R} \underset{\left(k \times 1\right)}{b} - \underset{\left(m \times 1\right)}{r}
\right)^{'}

&\times \\

\left(
\underset{\left(1 \times 1\right)}{\sigma^{2}}\underset{\left(m \times k\right)}{R}\left(\underset{\left(k \times T\right)}{X^{'}}\underset{\left(T \times k\right)}{X}\right)^{-1}\underset{\left(k \times m\right)}{R^{'}}
\right)^{-1}

&\times \\

\left(
\underset{\left(m \times k\right)}{R} \underset{\left(k \times 1\right)}{b} - \underset{\left(m \times 1\right)}{r}
\right)

&\div m

\end{align}





Check Hamilton based on infinite sample results...





See Hamilton (1994), p. 280

Let $S$ represent the long-run variance matrix of the vector process $y_t$, i.e., 

\begin{align}
\underset{\left(n \times n\right)}{S} &\equiv \lim_{T \rightarrow \infty} T \; \text{E} \left[\underset{\left(n \times 1\right)}{\left(\overline{y}_{T} - \mu\right)}\underset{\left(1 \times n\right)}{\left(\overline{y}_{T} - \mu\right)^{'}}\right]
\\
\phantom{\underset{\left(n \times n\right)}{S}} &\equiv \sum_{v=-\infty}^{\infty}\underset{\left(n \times n\right)}{\Gamma_{v}}
\end{align}

For $y_t$ generated by an MA(q) process this implies

\begin{align}
\underset{\left(n \times n\right)}{S} &= \sum_{v=-q}^{q}\underset{\left(n \times n\right)}{\Gamma_{v}}
\end{align}

which could be estimated by (natural estimator)

\begin{align}
\underset{\left(n \times n\right)}{\widehat{S}} &= \sum_{v=-q}^{q}\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}}
\\
\phantom{\underset{\left(n \times n\right)}{\widehat{S}}} &= \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}}+\sum_{v=1}^{q}\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}^{'}}
\end{align}

with

\begin{align}
\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}} = \frac{1}{T}\sum_{t=v+1}^{T}\underset{\left(n \times 1\right)}{\left(y_{t} - \overline{y}\right)}\underset{\left(1 \times n\right)}{\left(y_{t} - \overline{y}\right)^{'}}
\end{align}

Note, this gives a consistent estimate of the asymptotic variance of the sample mean for a broad class of processes exhibiting time-dependent heteroskedasticity and autocorrelation.

* $\widehat{S} \underset{p}{\rightarrow} S$ 
* But with $\widehat{S}$ potentially negative definite in finite sample.

<hr>

Newey and West (1987)

<!-- The estimator potentially results in a negative definite estimate. -->

\begin{align}
\underset{\left(n \times n\right)}{\widehat{S}} = \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}}+\sum_{v=1}^{q}\left(1-\frac{v}{q+1}\right)\left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}^{'}}\right)
\end{align}

again with,

\begin{align}
\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}} = \frac{1}{T}\sum_{t=v+1}^{T}\underset{\left(n \times 1\right)}{\left(y_{t} - \overline{y}\right)}\underset{\left(1 \times n\right)}{\left(y_{t} - \overline{y}\right)^{'}}
\end{align}

with the following properties

* $\widehat{S}$ is positive semidefinite by construction
* For $q \rightarrow \infty$ and $T \rightarrow \infty$ with $q/T^{1/4} \rightarrow 0$, $\widehat{S} \rightarrow S$ 

This is based on the Bartlett kernel...

```{r}

sandwich__bwNeweyWest <- function(x, order.by = NULL,
                                  kernel = c("Bartlett", "Parzen", "Quadratic Spectral", "Truncated", "Tukey-Hanning"),
                                  weights = NULL, prewhite = 1, ar.method = "ols", data = list(), ...) {
  
  
  
  if (is.list(x) && !is.null(x$na.action)) {
    class(x$na.action) <- "omit"
  }
  kernel <- match.arg(kernel)
  if (kernel %in% c("Truncated", "Tukey-Hanning")) {
    stop(paste("Automatic bandwidth selection only available for ", 
               dQuote("Bartlett"), ", ", dQuote("Parzen"), " and ", 
               dQuote("Quadratic Spectral"), " kernel. Use ", sQuote("bwAndrews"), 
               " instead.", sep = ""))
  }
  prewhite <- as.integer(prewhite)
  
  # handle umat of interest
  umat <- if (inherits(x, "matrix")) {
    x
  } else {
    estfun(x)[, , drop = FALSE]
  }
  if (is.zoo(umat)) {
    umat <- as.matrix(coredata(umat))
  }
  n <- nrow(umat)
  k <- ncol(umat)
  
  # handle ordering
  if (!is.null(order.by)) {
    if (inherits(order.by, "formula")) {
      z <- model.matrix(order.by, data = data)
      z <- as.vector(z[, ncol(z)])
    } else {
      z <- order.by
    }
    index <- order(z)
  } else {
    index <- 1:n
  }
  umat <- umat[index, , drop = FALSE]
  
  # ???
  if (is.null(weights)) {
    weights <- rep(1, k)
    unames <- colnames(umat)
    if (!is.null(unames) && "(Intercept)" %in% unames) {
      weights[which(unames == "(Intercept)")] <- 0
    } else {
      res <- try(as.vector(rowMeans(estfun(x)/model.matrix(x), na.rm = TRUE)), silent = TRUE)
      if (inherits(res, "try-error")) {
        res <- try(residuals(x), silent = TRUE)
      }
      if (!inherits(res, "try-error")) {
        weights[which(colSums((umat - res)^2) < 1e-16)] <- 0
      }
    }
    if (all(weights <= 0)) {
      weights <- rep(1, length.out = k)
    }
  } else {
    weights <- rep(weights, length.out = k)
  }
  if (length(weights) < 2) {
    weights <- 1
  }
  
  # preliminary q (Ham) or P (MHH, Table 9.1)
  mrate <- switch(kernel,
                  Bartlett = 2/9,
                  Parzen = 4/25,
                  `Quadratic Spectral` = 2/25)
  m <- floor(ifelse(prewhite > 0, 3, 4) * (n/100)^mrate)
  
  if (prewhite > 0) {
    var.fit <- ar(umat, order.max = prewhite, demean = FALSE, aic = FALSE, method = ar.method)
    if (inherits(var.fit, "try-error")) {
      stop(sprintf("VAR(%i) prewhitening of estimating functions failed", prewhite))
    }
    umat <- as.matrix(na.omit(var.fit$resid))
    n <- n - prewhite
  }
  
  hw <- umat %*% weights
  sigmaj <- function(j) { sum(hw[1:(n - j)] * hw[(j + 1):n])/n }
  sigma <- sapply(0:m, sigmaj)
  s0 <- sigma[1] + 2 * sum(sigma[-1])
  s1 <- 2 * sum(1:m * sigma[-1])
  s2 <- 2 * sum((1:m)^2 * sigma[-1])
  
  qrate <- 1/(2 * ifelse(kernel == "Bartlett", 1, 2) + 1)
  
  # updated q (Ham) or P (MHH, Table 9.1)
  rval <- switch(kernel,
                 Bartlett = { 1.1447 * ((s1/s0)^2)^qrate },
                 Parzen = { 2.6614 * ((s2/s0)^2)^qrate },
                 `Quadratic Spectral` = { 1.3221 * ((s2/s0)^2)^qrate })
  
  rval <- rval * (n + prewhite)^qrate
  
  return(rval)
  
}

sandwich__NeweyWest <- function(x, lag = NULL, order.by = NULL, prewhite = TRUE, adjust = FALSE, 
                                diagnostics = FALSE, sandwich = TRUE, ar.method = "ols", 
                                data = list(), verbose = FALSE) {
  
  
  
  if (is.null(lag)) {
    lag <- floor(bwNeweyWest(x, order.by = order.by, prewhite = prewhite, ar.method = ar.method, data = data))
  }
  if (verbose) {
    cat(paste("\nLag truncation parameter chosen:", lag, "\n"))
  }
  myweights <- seq(1, 0, by = -(1/(lag + 1)))
  
  vcovHAC(x, order.by = order.by, prewhite = prewhite, weights = myweights, 
          adjust = adjust, diagnostics = diagnostics, sandwich = sandwich, 
          ar.method = ar.method, data = data)
  
}

```

where:

* `weights`: ???
* `m`: $q$ in Hamilton, 1994, or $P$ in Martin et. al., 2013



<hr>

Spectral-Based Estimator

Note, if $y_t$ is covariance stationary, then $S$ has the interpretation as he autocovariance-generating function defined as

\begin{align}
G_{Y}\left(z\right) \equiv \sum_{v=-\infty}^{\infty}\underset{\left(n \times n\right)}{\Gamma_{v}z^{v}}
\end{align}

evaluated at $z=1$, or, equivalently, as $2\pi$ times the population spectrum at frequency zero:

\begin{align}
S &= \sum_{v=-\infty}^{\infty}\underset{\left(n \times n\right)}{\Gamma_{v}}
\\
\phantom{S} &= 2\pi \; \underset{\left(n \times n\right)}{s_{Y}\left(0\right)}
\end{align}

<hr>

(Kernel-base estimator of) Gallant (1987)

\begin{align}
\underset{\left(n \times n\right)}{\widehat{S}} = \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}}+\sum_{v=1}^{q}k\left(\frac{v}{q+1}\right)\left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}^{'}}\right)
\end{align}

with the spectral kernel

\begin{align}
k\left(z\right) = 
\begin{cases}
1-6z^2+6z^3 & \text{ for } 0 \leq z \leq \frac{1}{2} \\
2\left(1-z\right)^3 & \text{ for } \frac{1}{2} \leq z \leq 1 \\
0 & \text{ otherwise}. \\
\end{cases}
\end{align}

So, for $q=2$ we get:

\begin{align}
\underset{\left(n \times n\right)}{\widehat{S}} &= \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}} + k\left(\frac{1}{2+1}\right) \left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{1}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{1}^{'}}\right) + k\left(\frac{2}{2+1}\right) \left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{2}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{2}^{'}}\right)
\\
\phantom{\underset{\left(n \times n\right)}{\widehat{S}}} &= \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}} + \left(1-6\left(\frac{1}{3}\right)^2 + 6\left(\frac{1}{3}\right)^3\right) \left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{1}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{1}^{'}}\right) + \left(2\left(1-\frac{2}{3}\right)^3 \right) \left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{2}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{2}^{'}}\right)
\\
\phantom{\underset{\left(n \times n\right)}{\widehat{S}}} &= \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}} + \frac{5}{9}\left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{1}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{1}^{'}}\right) + \frac{2}{27}\left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{2}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{2}^{'}}\right)
\end{align}

(Kernel-base estimator of) Andrews (1991)

\begin{align}
\underset{\left(n \times n\right)}{\widehat{S}} = \frac{T}{T-k_x} \left( \underset{\left(n \times n\right)}{\widehat{\Gamma}_{0}}+\sum_{v=1}^{T-1}k\left(\frac{v}{q+1}\right)\left(\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}}+\underset{\left(n \times n\right)}{\widehat{\Gamma}_{v}^{'}}\right)\right)
\end{align}

Note, whereas the estimator proposed by Newey and West (1987) and Gallant (1987) uses a fixed number of estimated autocovariances $\widehat{\Gamma}_{v}$, the estimator proposed by Andrews (1991) uses all $T-1$ estimated autocovariances $\widehat{\Gamma}_{v}$.

However, there is still a bandwidth parameter $q$ to be chosen for constructing the kernel.




